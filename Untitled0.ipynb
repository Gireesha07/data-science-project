{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/PcxRlJPMNJ6wzxBudO+V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gireesha07/data-science-project/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UCPLSEnvTvv",
        "outputId": "125ae179-7776-4626-c443-8c233e0b97da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searched folders: ['.', '/mnt/data']\n",
            "Found files:\n",
            "  ./ratings.csv\n",
            "  ./movies.csv\n",
            "\n",
            "Auto-detected files:\n",
            " movies: ./movies.csv\n",
            " ratings: ./ratings.csv\n",
            " users: None\n",
            "\n",
            "Loaded shapes -> movies: (62423, 3) ratings: (1743832, 4) users: None\n",
            "Filling 1 missing/invalid timestamps with random values.\n",
            "\n",
            "Ratings preview:\n",
            "   userId  movieId  rating   timestamp\n",
            "0       1      296     5.0  1147880044\n",
            "1       1      306     3.5  1147868817\n",
            "2       1      307     5.0  1147868828\n",
            "3       1      665     5.0  1147878820\n",
            "4       1      899     3.5  1147868510\n",
            "\n",
            "Train size: (1395065, 4), Test size: (348767, 4)\n",
            "\n",
            "Building item-user matrix...\n",
            "Computing REDUCED item-item similarity on top-2000 items.\n",
            "\n",
            "Building user-item matrix for SVD...\n",
            "user-item shape: (9845, 18315)\n",
            "Using k = 50\n",
            "Predictions shape: (9845, 18315)\n",
            "\n",
            "Evaluating on sample test users...\n"
          ]
        }
      ],
      "source": [
        "# complete_recommender_autodetect_safe.py\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse.linalg import svds\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "\n",
        "# ---------------------------\n",
        "# Search for dataset files in common locations\n",
        "# ---------------------------\n",
        "search_dirs = [\".\", \"/mnt/data\"]\n",
        "candidates = []\n",
        "for d in search_dirs:\n",
        "    if not os.path.exists(d):\n",
        "        continue\n",
        "    candidates += glob.glob(os.path.join(d, \"*.csv\"))\n",
        "    candidates += glob.glob(os.path.join(d, \"*.xlsx\"))\n",
        "    candidates += glob.glob(os.path.join(d, \"*.xls\"))\n",
        "\n",
        "print(\"Searched folders:\", search_dirs)\n",
        "print(\"Found files:\")\n",
        "for f in candidates:\n",
        "    print(\" \", f)\n",
        "\n",
        "# ---------------------------\n",
        "# Heuristic detection of file role by sampling column names\n",
        "# ---------------------------\n",
        "def detect_role(path):\n",
        "    try:\n",
        "        if path.lower().endswith((\".xls\", \".xlsx\")):\n",
        "            df = pd.read_excel(path, nrows=3)\n",
        "        else:\n",
        "            df = pd.read_csv(path, nrows=3)\n",
        "    except Exception:\n",
        "        return None\n",
        "    cols = [c.lower().replace(\" \", \"\") for c in df.columns]\n",
        "    if any(c in cols for c in [\"userid\",\"user_id\",\"user\"]) and any(c in cols for c in [\"movieid\",\"movie_id\",\"movie\"]) and any(c in cols for c in [\"rating\",\"score\"]):\n",
        "        return \"ratings\"\n",
        "    if any(c in cols for c in [\"movieid\",\"movie_id\",\"id\"]) and any(c in cols for c in [\"title\",\"name\"]):\n",
        "        return \"movies\"\n",
        "    if any(c in cols for c in [\"userid\",\"user_id\",\"user\"]) and any(c in cols for c in [\"name\",\"location\",\"city\",\"age\"]):\n",
        "        return \"users\"\n",
        "    return None\n",
        "\n",
        "detected = {\"movies\": None, \"ratings\": None, \"users\": None}\n",
        "for f in candidates:\n",
        "    role = detect_role(f)\n",
        "    if role and detected.get(role) is None:\n",
        "        detected[role] = f\n",
        "\n",
        "# fallback name-based heuristics\n",
        "if detected[\"ratings\"] is None:\n",
        "    for f in candidates:\n",
        "        name = os.path.basename(f).lower()\n",
        "        if name.startswith((\"ratings\",\"rating\",\"interactions\",\"data\")) or \"rating\" in name:\n",
        "            detected[\"ratings\"] = f\n",
        "            break\n",
        "if detected[\"movies\"] is None:\n",
        "    for f in candidates:\n",
        "        name = os.path.basename(f).lower()\n",
        "        if name.startswith((\"movies\",\"movie\",\"titles\")) or \"movie\" in name:\n",
        "            detected[\"movies\"] = f\n",
        "            break\n",
        "\n",
        "print(\"\\nAuto-detected files:\")\n",
        "print(\" movies:\", detected[\"movies\"])\n",
        "print(\" ratings:\", detected[\"ratings\"])\n",
        "print(\" users:\", detected[\"users\"])\n",
        "\n",
        "if detected[\"movies\"] is None or detected[\"ratings\"] is None:\n",
        "    raise SystemExit(\"Could not automatically find both movies & ratings files. Place them in current dir or /mnt/data and name them clearly (movies.csv / ratings.csv).\")\n",
        "\n",
        "# ---------------------------\n",
        "# Safe load function\n",
        "# ---------------------------\n",
        "def safe_load(path):\n",
        "    if path.lower().endswith((\".xls\", \".xlsx\")):\n",
        "        return pd.read_excel(path)\n",
        "    else:\n",
        "        return pd.read_csv(path)\n",
        "\n",
        "movies = safe_load(detected[\"movies\"])\n",
        "ratings = safe_load(detected[\"ratings\"])\n",
        "users = safe_load(detected[\"users\"]) if detected[\"users\"] else None\n",
        "\n",
        "print(\"\\nLoaded shapes -> movies:\", getattr(movies, \"shape\", None), \"ratings:\", getattr(ratings, \"shape\", None), \"users:\", getattr(users, \"shape\", None))\n",
        "\n",
        "# ---------------------------\n",
        "# Normalize column names\n",
        "# ---------------------------\n",
        "def normalize_cols(df):\n",
        "    df = df.copy()\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    colmap = {}\n",
        "    for c in df.columns:\n",
        "        lc = c.lower().replace(\" \", \"\")\n",
        "        if lc in (\"userid\",\"user_id\",\"user\"):\n",
        "            colmap[c] = \"userId\"\n",
        "        elif lc in (\"movieid\",\"movie_id\",\"movie\"):\n",
        "            colmap[c] = \"movieId\"\n",
        "        elif lc in (\"rating\",\"ratings\",\"score\"):\n",
        "            colmap[c] = \"rating\"\n",
        "        elif lc in (\"timestamp\",\"time\",\"ts\",\"date\"):\n",
        "            colmap[c] = \"timestamp\"\n",
        "        elif lc in (\"title\",\"name\"):\n",
        "            colmap[c] = \"title\"\n",
        "        elif lc in (\"genres\",\"genre\"):\n",
        "            colmap[c] = \"genres\"\n",
        "        elif lc in (\"location\",\"city\"):\n",
        "            colmap[c] = \"location\"\n",
        "    return df.rename(columns=colmap)\n",
        "\n",
        "movies = normalize_cols(movies)\n",
        "ratings = normalize_cols(ratings)\n",
        "if users is not None:\n",
        "    users = normalize_cols(users)\n",
        "\n",
        "# Keep only relevant ratings columns\n",
        "ratings = ratings[[c for c in [\"userId\",\"movieId\",\"rating\",\"timestamp\"] if c in ratings.columns]].copy()\n",
        "\n",
        "# ---------------------------\n",
        "# Safe timestamp handling\n",
        "# ---------------------------\n",
        "def ensure_timestamp(df, col=\"timestamp\"):\n",
        "    if col not in df.columns:\n",
        "        df[col] = np.random.randint(1577836800, 1704067200, size=len(df))\n",
        "        return df\n",
        "    # if numeric already, keep\n",
        "    if pd.api.types.is_integer_dtype(df[col]) or pd.api.types.is_float_dtype(df[col]):\n",
        "        return df\n",
        "    # try parse to datetime then to unix seconds\n",
        "    parsed = pd.to_datetime(df[col], errors='coerce')\n",
        "    df[col] = (parsed - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta(\"1s\")\n",
        "    return df\n",
        "\n",
        "ratings = ensure_timestamp(ratings, \"timestamp\")\n",
        "ratings['timestamp'] = pd.to_numeric(ratings['timestamp'], errors='coerce')\n",
        "missing_ts = ratings['timestamp'].isna().sum()\n",
        "if missing_ts > 0:\n",
        "    print(f\"Filling {missing_ts} missing/invalid timestamps with random values.\")\n",
        "    ratings.loc[ratings['timestamp'].isna(), 'timestamp'] = np.random.randint(1577836800, 1704067200, size=missing_ts)\n",
        "ratings['timestamp'] = ratings['timestamp'].astype(int)\n",
        "\n",
        "print(\"\\nRatings preview:\")\n",
        "print(ratings.head())\n",
        "\n",
        "# ---------------------------\n",
        "# Ensure movies mapping exists\n",
        "# ---------------------------\n",
        "if 'movieId' not in movies.columns or 'title' not in movies.columns:\n",
        "    movies = pd.DataFrame({\"movieId\": sorted(ratings['movieId'].unique())})\n",
        "    movies['title'] = movies['movieId'].apply(lambda x: f\"Movie {int(x)}\")\n",
        "\n",
        "movie_titles = movies.set_index('movieId')['title'].to_dict()\n",
        "\n",
        "# ---------------------------\n",
        "# Train/test split (time-based)\n",
        "# ---------------------------\n",
        "ratings = ratings.sort_values('timestamp').reset_index(drop=True)\n",
        "split_idx = int(len(ratings) * 0.8)\n",
        "train = ratings.iloc[:split_idx].copy()\n",
        "test = ratings.iloc[split_idx:].copy()\n",
        "print(f\"\\nTrain size: {train.shape}, Test size: {test.shape}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Popularity baseline\n",
        "# ---------------------------\n",
        "popularity_rank = train.groupby('movieId').size().sort_values(ascending=False).index.tolist()\n",
        "def recommend_popular(user_id, train_df=train, N=10):\n",
        "    seen = set(train_df[train_df.userId==user_id].movieId.tolist())\n",
        "    return [m for m in popularity_rank if m not in seen][:N]\n",
        "\n",
        "# ---------------------------\n",
        "# Build item-user and item similarity (full or reduced) safely\n",
        "# ---------------------------\n",
        "print(\"\\nBuilding item-user matrix...\")\n",
        "item_user = train.pivot_table(index='movieId', columns='userId', values='rating').fillna(0)\n",
        "item_ids = item_user.index.tolist()\n",
        "item_index = {m:i for i,m in enumerate(item_ids)}\n",
        "\n",
        "max_items_for_dense = 5000\n",
        "use_reduced = False\n",
        "reduced_items = None\n",
        "reduced_index = None\n",
        "\n",
        "if item_user.shape[0] <= max_items_for_dense:\n",
        "    print(\"Computing FULL item-item cosine similarity (dense).\")\n",
        "    item_sim = cosine_similarity(item_user.values)\n",
        "else:\n",
        "    # reduced top-k similarity\n",
        "    topk = 2000\n",
        "    reduced_items = [m for m in popularity_rank[:topk] if m in item_ids]\n",
        "    print(f\"Computing REDUCED item-item similarity on top-{len(reduced_items)} items.\")\n",
        "    reduced_matrix = item_user.loc[reduced_items].values\n",
        "    item_sim = cosine_similarity(reduced_matrix)\n",
        "    reduced_index = {m:i for i,m in enumerate(reduced_items)}\n",
        "    use_reduced = True\n",
        "\n",
        "# ---------------------------\n",
        "# Safe item-CF recommender\n",
        "# ---------------------------\n",
        "def recommend_item_cf(user_id, train_df=train, N=10):\n",
        "    user_ratings = train_df[train_df.userId==user_id][['movieId','rating']]\n",
        "    if user_ratings.empty:\n",
        "        return recommend_popular(user_id, train_df, N)\n",
        "\n",
        "    scores = {}\n",
        "    seen = set(user_ratings.movieId.tolist())\n",
        "\n",
        "    for _, row in user_ratings.iterrows():\n",
        "        mid, r = int(row.movieId), float(row.rating)\n",
        "        if mid not in item_index:\n",
        "            continue\n",
        "        if not use_reduced:\n",
        "            sims = item_sim[item_index[mid]]\n",
        "            target_ids = item_ids\n",
        "        else:\n",
        "            if mid not in reduced_index:\n",
        "                # skip rated item not in reduced sim set\n",
        "                continue\n",
        "            sims = item_sim[reduced_index[mid]]\n",
        "            target_ids = reduced_items\n",
        "\n",
        "        for j, sim in enumerate(sims):\n",
        "            target_mid = target_ids[j]\n",
        "            if target_mid in seen:\n",
        "                continue\n",
        "            scores[target_mid] = scores.get(target_mid, 0.0) + sim * (r - 3.0)\n",
        "\n",
        "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    recs = [m for m,_ in ranked][:N]\n",
        "\n",
        "    if len(recs) < N:\n",
        "        for m in popularity_rank:\n",
        "            if m not in seen and m not in recs:\n",
        "                recs.append(m)\n",
        "            if len(recs) >= N:\n",
        "                break\n",
        "    return recs\n",
        "\n",
        "# ---------------------------\n",
        "# SVD Matrix Factorization\n",
        "# ---------------------------\n",
        "print(\"\\nBuilding user-item matrix for SVD...\")\n",
        "user_item = train.pivot_table(index='userId', columns='movieId', values='rating').fillna(0)\n",
        "R = user_item.values\n",
        "print(\"user-item shape:\", R.shape)\n",
        "\n",
        "R_mean = np.mean(R, axis=1)\n",
        "R_demeaned = R - R_mean.reshape(-1,1)\n",
        "k = min(50, min(R_demeaned.shape)-1)\n",
        "if k <= 0:\n",
        "    raise SystemExit(\"Not enough data for SVD. Need more users/movies.\")\n",
        "print(\"Using k =\", k)\n",
        "U, sigma, Vt = svds(R_demeaned, k=k)\n",
        "sigma = np.diag(sigma)\n",
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt) + R_mean.reshape(-1,1)\n",
        "preds_df = pd.DataFrame(all_user_predicted_ratings, index=user_item.index, columns=user_item.columns)\n",
        "print(\"Predictions shape:\", preds_df.shape)\n",
        "\n",
        "def recommend_svd(user_id, N=10, preds=preds_df, train_df=train):\n",
        "    if user_id not in preds.index:\n",
        "        return recommend_popular(user_id, train_df, N)\n",
        "    seen = set(train_df[train_df.userId==user_id].movieId.tolist())\n",
        "    user_row = preds.loc[user_id]\n",
        "    ranked = [m for m in user_row.sort_values(ascending=False).index if m not in seen]\n",
        "    recs = ranked[:N]\n",
        "    if len(recs) < N:\n",
        "        for m in popularity_rank:\n",
        "            if m not in seen and m not in recs:\n",
        "                recs.append(m)\n",
        "            if len(recs) >= N:\n",
        "                break\n",
        "    return recs\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation functions\n",
        "# ---------------------------\n",
        "def precision_recall_at_k(recommended, relevant, k=10):\n",
        "    if len(recommended) == 0:\n",
        "        return 0.0, 0.0\n",
        "    rec_k = recommended[:k]\n",
        "    hits = set(rec_k) & set(relevant)\n",
        "    precision = len(hits) / k\n",
        "    recall = len(hits) / (len(relevant) if len(relevant) > 0 else 1)\n",
        "    return precision, recall\n",
        "\n",
        "# ---------------------------\n",
        "# Quick evaluation on sample users\n",
        "# ---------------------------\n",
        "print(\"\\nEvaluating on sample test users...\")\n",
        "test_users_all = test.userId.unique()\n",
        "n_sample = min(500, len(test_users_all))\n",
        "test_users = np.random.choice(test_users_all, size=n_sample, replace=False)\n",
        "\n",
        "prec_pop=[]; rec_pop=[]\n",
        "prec_item=[]; rec_item=[]\n",
        "prec_svd=[]; rec_svd=[]\n",
        "\n",
        "rmse_preds=[]; rmse_truth=[]\n",
        "\n",
        "for uid in test_users:\n",
        "    user_test = test[test.userId==uid]\n",
        "    relevant = user_test[user_test.rating >= 4.0].movieId.tolist()\n",
        "    recs_pop = recommend_popular(uid)\n",
        "    recs_item = recommend_item_cf(uid)\n",
        "    recs_svd = recommend_svd(uid)\n",
        "    p,r = precision_recall_at_k(recs_pop, relevant); prec_pop.append(p); rec_pop.append(r)\n",
        "    p,r = precision_recall_at_k(recs_item, relevant); prec_item.append(p); rec_item.append(r)\n",
        "    p,r = precision_recall_at_k(recs_svd, relevant); prec_svd.append(p); rec_svd.append(r)\n",
        "    # RMSE\n",
        "    for _, row in user_test.iterrows():\n",
        "        mid = row.movieId\n",
        "        true_r = row.rating\n",
        "        if uid in preds_df.index and mid in preds_df.columns:\n",
        "            rmse_preds.append(preds_df.loc[uid, mid]); rmse_truth.append(true_r)\n",
        "\n",
        "def avg(a): return np.mean(a) if len(a)>0 else 0.0\n",
        "metrics = {\n",
        "    \"pop_prec@10\": avg(prec_pop), \"pop_rec@10\": avg(rec_pop),\n",
        "    \"item_prec@10\": avg(prec_item), \"item_rec@10\": avg(rec_item),\n",
        "    \"svd_prec@10\": avg(prec_svd), \"svd_rec@10\": avg(rec_svd),\n",
        "    \"svd_rmse\": sqrt(mean_squared_error(rmse_truth, rmse_preds)) if len(rmse_truth)>0 else None\n",
        "}\n",
        "\n",
        "print(\"\\nMetrics summary:\")\n",
        "for k,v in metrics.items():\n",
        "    print(f\"{k}: {v}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Print sample recommendations\n",
        "# ---------------------------\n",
        "def title_for(m):\n",
        "    return movie_titles.get(m, str(m))\n",
        "\n",
        "print(\"\\nSample SVD recommendations for 5 random test users:\")\n",
        "sample_u = np.random.choice(test.userId.unique(), size=min(5, len(test.userId.unique())), replace=False)\n",
        "for uid in sample_u:\n",
        "    recs = recommend_svd(uid, N=10)\n",
        "    print(f\"User {uid} ->\", [title_for(m) for m in recs])\n",
        "\n",
        "# Save preds\n",
        "try:\n",
        "    preds_df.to_csv(\"svd_predicted_ratings_autodetect.csv\")\n",
        "    print(\"\\nSaved preds to svd_predicted_ratings_autodetect.csv\")\n",
        "except Exception as e:\n",
        "    print(\"Could not save predictions:\", e)\n"
      ]
    }
  ]
}